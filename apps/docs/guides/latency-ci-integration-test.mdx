---
title: How to use OpenStatus in GitHub Actions to test latency.
description: Learn how to use OpenStatus for testing latency in GitHub Actions to verify your endpoint's performance.
---

## Introduction


In this guide, we will show you how to use OpenStatus for testing latency in GitHub Actions to verify your endpoint's performance. We'll deploy a basic API endpoint and run a latency test in a GitHub Action with OpenStatus. If the latency is higher than expected, we will roll back the deployment.

All the code used in this guide is available on [GitHub](https://github.com/openstatusHQ/github-action-rollback).


## Prerequisites

- An Endpoint to test (Cloudflare Workers, Vercel, Netlify, etc.)
- A GitHub Account
- An [OpenStatus](https://www.openstatus.dev) Account


## Our API Endpoint

For this guide, we are using a simple [Hono](https://www.hono.dev) server that returns `Hello OpenStatus!`.
We are deploying it on [Cloudflare Workers](https://workers.cloudflare.com/).

```typescript
import { Hono } from "hono";

const app = new Hono();

app.get("/", async (c) => {

  return c.text("Hello OpenStatus!");
});

export default app;
```


## Setting up the test

For the test, we are using the OpenStatus API to run a global latency test on our endpoint.
If the latency is higher than expected, we will roll back the deployment.
We expect our endpoint to have a 75th percentile latency of less than 1000ms in all regions.


```typescript
test("should fail if slow", async () => {

  // Let's warm our endpoint
  await fetch("https://github-action-rollback.thibaultleouay.workers.dev/");
  // Run the test
  const options = {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "x-openstatus-key": process.env.OPENSTATUS_API_KEY || "",
    },
    body: '{"url":"https://github-action-rollback.thibaultleouay.workers.dev/","method":"GET","regions":["ams","iad","gru"],"runCount":2,"aggregated":true}',
  };

  const data = await fetch("https://api.openstatus.dev/v1/check", options);
  const json = await data.json();
  const result = schema.parse(json);
  expect(result.aggregated.firstByte.p75 < 1000).toBe(true);
});
```
## Setting up the GitHub Actions

We will use GitHub Actions to deploy our endpoint and run the test.
We are using the bun CLI to deploy our endpoint instead of the Cloudflare Workers Action and run the test

```yaml

name: Deploy

on:
  push:
    branches:
      - main

jobs:
  deploy:
    name: Deploy 🔥
    runs-on: ubuntu-latest
    env:
      OPENSTATUS_API_KEY: ${{ secrets.OPENSTATUS_API_KEY }}
      CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
      CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}

    steps:
      - name: ⬇️ Checkout repo
        uses: actions/checkout@v3

      - name: 🔥 Install bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest

      - name: 📥 Download deps
        run: bun install

      - name: 🔥 Deploy
        run: bun run deploy


      - name: 🧪 Test
        run: bun test
        id: test

      - name: 🚀 Rollback
        if: failure() && steps.test.outcome == 'failure'
        run: bun run rollback

```


## Conclusion

We have successfully set up a GitHub Action that deploys our endpoint and runs a latency test with OpenStatus.
Don't ever let your users experience slow endpoints, use OpenStatus to monitor your endpoint's performance and roll back deployments if needed.